\newcommand{\F}{\mathcal{F}}
\renewcommand{\P}{\mathbb{P}}

\section*{Grundlagen}

Betrachtet wird Folge von Zufallsvariablen $(X_n)$ auf Wahrscheinlichkeitsraum $(\Omega,\F,\P)$ mit $X_n : \Omega \to S$. $S$ sei endlich oder abzählbar unendlich.

$X_n$ beschreibt Zustand des Systems zur Zeit $n$.

$(X_n)$ ist \emph{stochastischer Prozess} in diskreter Zeit.

\subsection*{Stochastische Matrizen}

Eine Matrix $P = (p_{ij})_{i,j \in S}$ heißt \emph{stochastisch}, falls $p_{ij} \geq 0$ und $\forall i \in S : \sum_{j \in S} p_{ij} = 1$ gilt.

Produkt stochastischer Matrizen ist stochastisch.

\section*{Homogene Markov-Ketten}

Eine Folge $X_0, X_1, X_2, \dots$ von $S$-wertigen ZV heißt \emph{homogene Markov-Kette} mit Übergangsmatrix $P$, falls für $\forall n \in \N$ und alle Zustände $i_k \in S$ mit $\P(X_0 = i_0,\dots,X_n = i_n) > 0$ gilt:

\vspace*{-4mm}
\begin{align*}
&\P(X_{n+1} = i_{n+1} | X_0 = i_0, \dots, X_n = i_n) \\
&= \P(X_{n+1} = i_{n+1} | X_n = i_n) \\
&= p_{i_n i_{n+1}}
\end{align*}

$p_{ij}$ heißen \emph{Übergangswahrscheinlichkeiten}.

$\nu(i) = \P(X_0=i)$ def. für $i \in S$ die \emph{Startverteilung}.

\spacing

Jede Folge unabhängiger ZV ist Markov-Kette.

Übergangswk. einer homogenen Markov-Kette hängen nicht vom Zeitpunkt des Übergangs ab.

\subsection*{Charakterisierung}

Es sind äquivalent:

\begin{enumerate}[label=(\alph*)]
	\item $(X_n)$ ist MK mit Übergangsmatrix $P$
	\item $\forall n \in \N_0, i_k \in S :$ \vspace*{-2mm} \\ $\P(X_k = i_k, 0 \leq k \leq n) = \P(X_0 = i_0) \displaystyle\prod_{k=0}^{n-1} p_{i_k i_{k+1}}$
	\item $\forall n \in \N_0, i_k \in S$ mit $\P(X_0 = i_0) > 0$: \\ $\P(X_k = i_k, 1 \leq k \leq n | X_0 = i_0) = \prod_{k=0}^{n-1} p_{i_k i_{k+1}}$
\end{enumerate}

\subsection*{$n$-Schritt Übergang}

Sei $P$ stochastische Matrix. Dann sind $p_{ij}^{(n)}$ von $P^n$ die \emph{$n$-Schritt-Übergangswahrscheinlichkeiten} zu $P$.

$\forall i, j \in S, m, n \in \N_0$ mit $\P(X_m = i) > 0 : \\ \P(X_{n+m} = j | X_m = i) = p_{ij}^{(n)}.$

$\forall j \in S, n \in \N : \P(X_n = j) = \sum_{j \in S} \P(X_0 = i) p_{ij}^{(n)}$

\subsection*{Chapman-Kolmogorov-Gleichung}

$p_{ij}^{(n+m)} = \displaystyle\sum_{k \in S} p_{ik}^{(n)} p_{kj}^{(m)}$ für $i, j \in S$.

\section*{Zustandsklassifikation}

Ein Zustand $i \in S$ \emph{führt nach} $j \in S$ (kurz $i \rightsquigarrow j$), falls $\exists n \in \N : p_{ij}^{(n)} > 0$.

Ein Zustand $i \in S$ \emph{kommuniziert mit} $j \in S$ ($i \leftrightarrow j$), falls $i \rightsquigarrow j$ und $j \rightsquigarrow i$ gelten.

\subsection*{Äquivalenzklassen}

Die Relation $i \sim j := (i \leftrightarrow j) \lor (i = j)$ definiert eine Äquivalenzrelation auf $S$.

Zustandsmenge $S$ lässt sich in Äquivalenzklassen $K(i) := \{j \in S | i \sim j\}$ partitionieren.

\spacing

$J \subset S$ ist \emph{abgeschlossen}, wenn $\not\exists j \in J, i \in S \setminus J : j \rightsquigarrow i$.

Die Markov-Kette $(X_n)$ ist \emph{irreduzibel}, falls $S$ nur aus einer Klasse besteht. d.h. $\forall i, j \in S, i \neq j : i \leftrightarrow j$.

\spacing

$J \subset S$ ist abg. gdw. $(p_{ij}, i,j \in J)$ stochastisch ist.

\subsection*{Eintrittszeit eines Zustands}

$T_i := \inf\{ n \in \N : X_n = i \}$ ist die zufällige Eintrittszeit der Markov-Kette in Zustand $i \in S$.

Für $i, j \in S, n \in \N$ sei definiert:

\vspace*{-4mm}
\begin{align*}
f_{ij}^{(n)} :&= \P(T_j = n | X_0 = i) = \P_i(T_j = n) \\
&= \P(X_n = j, X_\nu \neq j (1 \leq \nu < n) | X_0 = i)
\end{align*}

$f_{ij}^{(n)}$ beschreibt die Wahrscheinlichkeit von $i$ startend nach genau $n$ Schritten in $j$ anzugelangen.

$f_{ij}^* := \sum_{n=0}^\infty f_{ij}^{(n)} = \P_i(\exists n \in \N : X_n = j)$

\spacing

Ein Zustand $i \in S$ mit $f_{ii}^* = 1$ ist \emph{rekurrent}.

Gilt $f_{ii}^* \neq 1$ so ist $i \in S$ \emph{transient}.

$\forall n \in \N, i, j \in S : p_{ij}^{(n)} = \displaystyle\sum_{k=1}^n f_{ij}^{(k)} p_{jj}^{(n-k)}$

Zustand $i \in S$ ist rekurrent gdw. $\displaystyle\sum_{n = 0}^\infty p_{ii}^{(n)} = \infty$.

\subsubsection*{Solidaritätsprinzip}

Ist Zustand $i \in S$ rekurrent bzw. transient, so ist $\forall j \in K(i)$ seiner Klasse rekurrent bzw. transient.

\spacing

Liegen $i, j \in S$ in der selben rekurrenten Klasse, so gilt: $f_{ij}^* = f_{ji}^* = 1$.

\subsubsection*{Abgeschlossenheit}

Ist eine Klasse $K \subseteq S$ rekurrent so ist $S$ abgeschlossen, d.h. $(p_{ij}, i,j \in K)$ ist stochastisch.

\spacing

Ist eine Klasse $K \subseteq S$ abgeschlossen und endlich, so ist $K$ rekurrent.

\section*{Absorptionswahrscheinlichkeiten}

Zustandsmenge $S$ ist zerlegbar in rekurrente Klassen $K_1, \dots, K_m$ und eine Menge transienter Zustände $T$ s.d. $S = T \cup K_1 \cup \cdots \cup K_m$.

\vspace*{1mm}

Sei $\tau = \inf\{ n \geq 0 | X_n \notin T\}$ die Austrittszeit aus der transienten Menge, d.h. der Zeitpunkt der Absorption in eine der rekurrenten Klassen.

\vspace*{1mm}

Sei $i \in T, k \in T^c$ und $u_{ik} = \P_i(X_\tau = k)$.

\spacing

Für $i \in T, j \in T^c$ gilt: $u_{ij} = \displaystyle\sum_{k \in T} p_{ik} u_{kj} + p_{ij}$

\section*{Stationäre Verteilungen}

Sei $(X_n)$ MK mit Übergangsmatrix $P$ und Startverteilung $\nu$. Dann ist $X_n \sim \nu \cdot P^n$. Die Verteilung hängt i.A. von $n$ und $\nu$ ab.

\vspace*{1mm}

Ein Maß $\nu : S \to \R_{\geq 0}$ ist \emph{invariant} für $P$, falls $\nu \cdot P = \nu$ d.h: $\sum_{i \in S} \nu(i) \cdot p_{ij} = \nu(j)$ für $j \in S$

\vspace*{1mm}

Ist $\nu$ eine Verteilung (d.h. $\sum_{i \in S} \nu(i) = 1$) und invariant für $P$, so ist $\nu$ eine \emph{stationäre Verteilung}.

\vspace*{1mm}

Eine mit stationärer Verteilung $\nu$ gestartete MK hat zu jedem Zeitpunkt Verteilung $\nu$:

$\P_\nu(X_n = j) = \sum_{i \in S} \nu(i) \cdot p_{ij}^{(n)} = \nu(j)$

\subsection*{Existenz und Eindeutigkeit}

Sei $(X_n)$ irreduzibel und rekurrent und $k \in S$. Dann ist ein Maß $\gamma_k$ definiert mit Eigenschaften:

$\gamma_k(i) := \mathbb{E}_k\left[\displaystyle\sum_{n=1}^{T_k} \mathbbm{1}_{[X_n=i]}\right]$ für bel. $k \in S$

\begin{enumerate}[label=(\alph*)]
	\item $\gamma_k$ ist ein invariantes Maß
	\item $0 < \gamma_k < \infty$
	\item $\gamma_k$ ist das einzige invariante Maß mit $\gamma_k(k) = 1$. Es ist eindeutig bis auf Vielfache.
\end{enumerate}

Ist $S$ zusätzlich endlich existiert eine eindeutige stationäre Verteilung.

Ist $(X_n$ jedoch neben irreduzibel auch transient, existiert keine stationäre Verteilung.

\subsection*{Mittlere Rückkehrzeit}

Die \emph{mittlere Rückkehrzeit} des Zustands $i \in S$ ist:

\vspace*{-4mm}
\begin{align*}
m_i :&= \mathbb{E}_i[T_i] = \sum_{n=1}^\infty n \cdot \P_i(T_i = n) + \infty \cdot (1-f_{ii}^*) \\
&= \sum_{n=1}^\infty n \cdot f_{ii}^{(n)} + \infty \cdot (1- f_{ii}^*)
\end{align*}

$i \in S$ ist \emph{positiv rekurrent}, wenn $m_i < \infty$.

$i \in S$ ist \emph{nullrekurrent}, wenn $m_i = \infty$.

\subsection*{Positive Rekurrenz und Verteilung}

Für irreduzible $(X_n)$ sind äquivalent:

\begin{enumerate}[label=(\alph*)]
	\item Es existiert eine stationäre Verteilung
	\item $\exists i \in S : i$ ist positiv rekurrent
	\item $\forall i \in S : i$ ist positiv rekurrent
\end{enumerate}

Stationäre Verteilung ist eind. geg.: $\pi(i) = \frac{1}{m_i}$

Sei $\nu$ stationäre Verteilung, dann gilt:

$$\nu(i) = \frac{\gamma_k(i)}{\sum_{j \in S} \gamma_k(j)} = \frac{\mathbb{E}_k[\sum_{n=1}^{T_k} \mathbbm{1}_{X_n = i}]}{\mathbb{E}_k[T_k]}$$

$\nu(i)$ ist also durchschnittlicher Bruchteil der Zeit, den die MK in $i \in S$ verbringt.

\subsection*{Trichotomie irreduzibler Markov-Ketten}

Eine irreduzible MK entspricht einem der Fälle:

\begin{enumerate}[label=(\alph*)]
	\item MK ist transient und es existiert keine stationäre Verteilung.
	\item MK ist nullrekurrent und es existiert ein bis auf Vielfache eindeutiges invariantes Maß aber keine stationäre Verteilung.
	\item MK ist positiv rekurrent, es gilt $\forall i, j \in S : \mathbb{E}_i[T_j] < \infty$ und es ex. stationäre Verteilung.
\end{enumerate}

\subsection*{Konvergenz gegen stationäre Verteilung}

Unter Voraussetzungen ist es möglich, dass die Verteilung des Zustands einer MK langfristig gegen eine stationäre Verteilung konvergiert.

\subsubsection*{Totalvariationsabstand}

Seien $\mu, \nu$ W-Maße auf $S$.

$d(\mu, \nu) := \sup_{A \subset S} |\mu(A)-\nu(A)|$

ist der \emph{Totalvariationsabstand} zwischen $\mu$ und $\nu$.

\vspace*{1mm}

Es gilt $d(\mu,\nu) = \frac{1}{2} \sum_{i \in S} |\mu(i) - \nu(i)|$.

\subsubsection*{Periode eines Zustands}

Die Periode eines Zustands $i \in S$ ist geg. als:

\vspace*{-2mm}
$$d_i = ggT\{ n \in \N : p_{ii}^{(n)} > 0 \}$$

Zustände mit $d_i = 1$ heißen \emph{aperiodisch}.

$P$ ist irreduzibel und aperiodisch gdw.:

$\forall i, j \in S \exists n_0 \in \N \forall n \geq n_0 : p_{ij}^{(n)} > 0$.

\subsubsection*{Konvergenzsatz}

Sei MK $(X_n)$ irreduzibel, aperiodisch und positiv rekurrent mit Startverteilung $\nu$ und stationärer Verteilung $\pi$. Dann: $\lim_{n \to \infty} d(\nu P^n, \pi) = 0$

Insb.: $\lim_{n\to\infty} p_{ij}^{(n)} = \pi(j) = \frac{1}{m_j}$.

\subsubsection*{Mischungszeit}

Sei $(X_N)$ irreduzible, aperiodische, positiv rekurrente MK mit stationärer Verteilung $\pi$ und:

$d(n) := \sup_{i \in S} d(\delta_i P^n,\pi)$

Für $\epsilon > 0$ ist $t_{mix}(\epsilon) = \min\{ n \in \N : d(n) \leq \epsilon \}$ die \emph{Mischungszeit}. d.h. die Zeitdauer, nach der die Verteilung von $X_{t_{mix}}$ in etwa der stationären Verteilung $\pi$ entspricht.

\section*{Reversibilität}

Sei $(X_n)$ MK mit Übergangsmatrix $P$, Zustandsraum $S$ und stationärer Verteilung $\pi$ mit $\forall i \in S : \pi(i) > 0$. Definiere $Q = (q_{ij})_{i,j \in S}$:

\vspace*{-2mm}
$$q_{ij} := \frac{\pi(j)}{\pi(i)} p_{ij}, \ i,j \in S$$

Dann ist $Q$ stochastisch und für $X_0 \sim \pi$ gilt:

\vspace*{-4mm}
\begin{align*}
\P(X_n = j | X_{n+1} = i) &= \frac{\P(X_{n+1} = i | X_n = j) \P(X_n = j)}{\P(X_{n+1} = i)} \\
&= q_{ij}
\end{align*}

Somit ist $Q$ Übergangsmatrix der Markov-Kette, wenn die Zeit rückwärts läuft.

\vspace*{1mm}

Eine MK mit positiver stationärer Verteilung $\pi$ ist \emph{reversibel}, wenn: $\forall i, j \in S : \pi(i)p_{ij} = \pi(j)p_{ji}$

\vspace*{1mm}

In diesem Fall gilt $P=Q$ und die Zeitumkehr verhält sich statistisch wie $(X_n)$ selbst.

\section*{Markov Chain Monte Carlo}

Sei $S$ endlich, $\pi$ Verteilung auf $S$. Ziel ist es, eine MK $(X_n)$ auf $S$ zu finden, s.d. $\pi$ ihre stationäre Verteilung ist.

Dies ist hilfreich, wenn nach $\pi$ verteilte Zufallszahlen schwierig zu erzeugen sind. Es ist einfacher $(X_n)$ bis zu Zeitpunkt $n_0$ ablaufen zu lassen und $X_{n_0}$ als Approximation von $\pi$ zu nutzen.

\subsection*{Metropolis-Kette}

Sei $K$ irreduzible, symmetrische Übergangsmatrix auf $S$. Wählen $P = (p_{ij})$ mit:

$$p_{ij} = \begin{cases} K_{ij}\left(\frac{\pi(j)}{\pi(i)} \land 1\right) & i \neq j \\ 1 - \sum_{k \neq i} K_{ik}\left(\frac{\pi(j)}{\pi(i)} \land 1\right) & i=j \end{cases}$$

Dann besitzt die MK mit Übergangsmatrix $P$ die stationäre Verteilung $\pi$.

\section*{Markov-Ketten in stetiger Zeit}

Sei $(N_t)_{t\geq 0}$ Familie messbarer Zufallsvariablen $N_t : \Omega \to \N_0$. Diese bildet \emph{stochastischen Prozess in stetiger Zeit}.

\subsection*{Poisson-Prozess}

Die Familie $(N_t)_{t\geq 0}$ erfülle:

\begin{enumerate}[label=(\alph*)]
	\item Alle Pfade $t \mapsto N(t,\omega)$ liegen in $D_0 := \{ f : [0,\infty) \to \N_0 | f(0) = 0, f \uparrow, f \text{ rechtsstetig}\}$.
	\item $(N_t)_{t\geq0}$ hat unabhängige Zuwächse: $\forall n \in \N \\ \forall 0 \leq t_0 \leq \cdots \leq t_n$ sind $N_{t_0}, N_{t_1}-N_{t_0}, \dots, \\ N_{t_n}-N_{t_{n-1}}$ stochastisch unabhängig
	\item $(N_t)_{t\geq0}$ hat stationäre Zuwächse d.h. $\forall t > 0$ ist Verteilung $N_{s+t}-N_s$ von $s$ unabhängig
	\item Ereigniss treten einzeln auf d.h.: \\ $\P(N_h \geq 2) = o(h)$ mit $h \downarrow 0$
\end{enumerate}

$(N_t)$ hat mit Wahrscheinlichkeit $1$ nur Sprünge der Höhe $1$ und: $\exists \lambda > 0 \forall s, t \geq 0 : N_{s+t}-N_s$ ist Poisson-verteilt mit Parameter $\lambda t$. Die Zeiten zwischen konsekutiven Sprüngen sind unabhängig und exponentialverteilt mit Parameter $\lambda$.

Der Prozess $(N_t)$ heißt \emph{Poisson-Prozess} mit $\lambda > 0$.

\subsection*{Markov-Eigenschaft}

Ein stochastischer Prozess $(X_t)_{t\geq0}$ mit abzählbarem Zustandsraum $S$ heißt \emph{(homogene) Markov-Kette}, wenn:

$\forall n \in \N$, $t, h > 0, i_k \in S$ sowie $\forall 0 \leq t_0 < t_1 < \cdots < t_n$ mit $\P(X_{t_k} = i_k, 0 \leq k \leq n) > 0 : $

\vspace*{-4mm}
\begin{align*}
&\P(X_{t_n+h} = i_{n+1} | X_{t_k} = i_k, 0 \leq k \leq n) \\
&= \P(X_{t_n+h} = i_{n+1} | X_{t_n} = i_n) \\
&= \P(X_{t+h} = i_{n+1} | X_t = i_n)
\end{align*}

\subsection*{Intensitätsmatrix}

Sei $\{P(t), t \geq 0\}$ eine \emph{Standardübergangsmatrizen-funktion}. Dann sind alle $p_{ij}(t)$ in $0$ rechtseitig differenzierbar d.h.: $\forall i, j \in S :$

\vspace*{-2mm}
$$q_{ij} := \lim_{t\downarrow0} \frac{1}{t} (p_{ij}(t) - \delta_{ij})$$

Die Matrix $Q := (q_{ij})$ ist die \emph{Intensitätsmatrix} bzw. der \emph{infinitesimale Erzeuger} von $\{P(t),t \geq 0\}$.

\subsubsection*{Intensitätsmatrix des Poisson-Prozesses}

Für einen Poisson-Prozess $(N_t)$ ergibt sich die Übergangsmatrizenfunktion:

$$p_{ij}(t) = \begin{cases} e^{-\lambda t} \frac{(\lambda t)^{j-i}}{(j-i)!} & j \geq i \\ 0 & \text{sonst}\end{cases}$$

Demenstsprechend gilt:

\vspace*{-4mm}
$$\lim_{t\downarrow0} \frac{1}{t} (p_{ij}(t) - \delta_{ij}) = \begin{cases} \lambda & j = i+1 \\ -\lambda & j=i \\ 0 & \text{sonst}\end{cases}$$

Die Intensitätsmatrix des Poisson-Prozesses:

$$Q = \begin{pmatrix} -\lambda & \lambda & 0 & 0 & \cdots \\ 0 & -\lambda & \lambda & 0 & \cdots \\ 0 & 0 & -\lambda & \lambda & \\ \vdots & \vdots & & & \ddots \end{pmatrix}$$
