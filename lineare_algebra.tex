\section*{Relationen}

Sei $R := A \times B$ eine Relation.

\subsection*{Linkstotal}

$\forall a \in A \exists b \in B : (a,b)  \in R$

\subsection*{Rechtstotal / Surjektiv}

$\forall b \in B \exists a \in A : (a,b) \in R \text{ bzw. } f(a)=b$

\subsection*{Linkseindeutig / Injektiv}

$\forall a_1, a_2 \in A \forall b \in B :$ \newline
\hspace*{5mm} $(a_1,b) \in R \land (a_2,b) \in R \implies a_1=a_2$

\subsection*{Rechtseindeutig}

$\forall a \in A \forall b_1, b_2 \in B:$ \newline
\hspace*{5mm} $(a,b_1) \in R \land (a,b_2) \in R \implies b_1=b_2$

\subsection*{Eigenschaften von Relationen}

\begin{description}[leftmargin=!,labelwidth=25mm]
	\item[reflexiv] $\forall x \in M : (x, x) \in R$
	\item[symmetrisch] $\forall x, y \in M : xRy \Leftrightarrow yRx$
	\item[antisymmetrisch] $\forall x, y \in M : xRy \land yRx \Rightarrow x=y$
	\item[transitiv] $\forall x, y, z \in M : xRy \land yRz \Rightarrow xRz$
\end{description}

\subsection*{Äquivalenzrelationen}

Eine Relation $R$ auf Menge $M$ ist Äquivalenzrelation, wenn sie reflexiv, symmetrisch und transitiv ist.

\section*{Gruppen}

$\star : M \times M \rightarrow M$ ist Verknüpfung auf Menge $M$ abhängig der Argument-Reihenfolge. Das Tupel $(M, \star)$ ist Gruppe, wenn:

\begin{enumerate}[label=(\alph*)]
	\item $\star$ ist assoziativ
	\item $\exists e \in M \forall x \in M : x \star e = e \star x = x$
	\item $\forall x \in M \exists y \in M : x \star y = y \star x = e$
\end{enumerate}

Ist $\star$ kommutativ, dann $(M, \star)$ abelsche Gruppe.

\subsection*{Assoziativität}

$\forall m_1, m_2, m_3 \in M : (m_1 \star m_2) \star m_3 = m_1 \star (m_2 \star m_3)$

\subsection*{Kommutativität}

$\forall m_1, m_2 \in M : m_1 \star m_2 = m_2 \star m_1$

\subsection*{Untergruppen}

$(M, \star)$ ist Gruppe. $(H, \circ)$ ist Untergruppe, wenn:

\begin{enumerate}[label=(\alph*)]
	\item $H \subseteq M$
	\item $(H, \circ)$ ist Gruppe
	\item $\forall h_1, h_2 \in H : h_1 \circ h_2 = h_1 \star h_2$
\end{enumerate}

\subsubsection*{Untergruppenkriterium}

$H \subseteq G$ ist Untergruppe von $G$ wenn:

$H \neq \emptyset \land \forall h_1, h_2 \in H : h_1 \star h_2^{-1} \in H$

\subsection*{Gruppenhomomorphismen}

Seien $(G, \star)$ und $(H, \circ)$ Gruppen. $f: G \rightarrow H$ ist Gruppenhomomorphismus wenn:

$\forall g_1, g_2 \in G: f(g_1 \star g_2) = f(g_1) \circ f(g_2)$

\subsubsection*{Eigenschaften von Homomorphismen}

\begin{enumerate}[label=(\alph*)]
	\item $f(e_G) = e_H$
	\item $\forall g \in G : f(g^{-1}) = f(g)^{-1}$
	\item $f(G)$ ist Untergruppe von $H$
	\item $f \in Hom(G, H)$ ist genau dann injektiv, wenn $Kern(f) = \{e_G\}$
\end{enumerate}

\subsection*{Weitere Homomorphismen}

\begin{enumerate}[label=(\alph*)]
	\item $f : G \rightarrow G$ ist Endomorphismus
	\item Bijektives $f: G \rightarrow H$ ist Isomorphismus
	\item Bijektives $f \in End(V)$ ist Automorphismus
\end{enumerate}

\section*{Ringe}

$(R, +, *)$ ist Ring, wenn:

\begin{enumerate}[label=(\alph*)]
	\item $(R, +)$ ist abelsche Gruppe
	\item $*$ ist assoziativ
	\item $\forall x \in R : 1_R * x = x * 1_R = x$
	\item $x*(y+z) = (x*y)+(x*z)$
	\item $(y+z)*x = (y*x)+(z*x)$
\end{enumerate}

Ist $*$ kommutativ, $(R, +, *)$ ein kommutativer Ring.

\subsection*{Teilringe}

Unter $+$ und $*$ geschlossene Teilmenge $T \subseteq R$ ist Teilring von $R$.

\subsection*{Ringhomomorphismen}

$\phi : R \rightarrow S$ ist Ringhomomorphismus, wenn:

\begin{enumerate}[label=(\alph*)]
	\item $\forall x, y \in R : \phi(x +_R y) = \phi(x) +_S \phi(y)$
	\item $\forall x, y \in R : \phi(x *_R y) = \phi(x) *_S \phi(y)$
	\item $\phi(1_R) = 1_S$
\end{enumerate}

\section*{Körper}

Ein Körper ist kommutativer Ring $K$ mit $0_K \neq 1_K$ und für den jedes $x \neq 0_K$ invertierbar ist.

\section*{Matrizen}

\subsection*{Invertierbare Matrizen}

Für einen kommutativen Ring $R$ ist die "general linear Group":

$GL_p(R) := \{ A \in R^{p \times p} | \exists B \in R^{p \times p} : AB = BA = I_p \}$

$A \in GL_p(R)$ sind invert. / reguläre Matrizen.

\subsection*{Elementarmatrizen}

$$R^{2 \times 3} \ni E_{2,3} = \begin{pmatrix}
	0 & 0 & 0 & 0 \\
	0 & 0 & 1 & 0
\end{pmatrix}$$

\subsection*{Äquivalenz von Matrizen}

$\exists S \in GL_q(K), T \in GL_p(K) : B = T A S$ ($A, B \in K^{p \times q}$)

\subsection*{Ähnlichkeit von Matrizen}

$A, \tilde A \in K^{d \times d}$ ähnlich $\Leftrightarrow \exists S \in GL_d(K) : \tilde A = S^{-1}AS$

Ähnliche Matrizen haben die gleiche Determinante, Spur und Rang.

\subsection*{Determinante}

\begin{enumerate}[label=(\alph*)]
	\item $det(A) \neq 0 \Leftrightarrow A \text{ ist invertierbar}$
	\item $det(A*B) = det(A) * det(B)$
	\item $det(A)^{-1} = det(A)^{-1}$ falls $A \in GL_n(K)$
	\item $det(A) = det(A^T)$
\end{enumerate}

\section*{Vektorräume}

Ein $K$-Vektorraum ist kommutative Gruppe $(V, +)$ mit skalarer Multiplikation $* : K \times V \rightarrow V, (a, v) \mapsto a * v$ sowie:

\begin{enumerate}[label=(\alph*)]
	\item $\forall v \in V : 1_K * v = v$
	\item $\forall a, b \in K \forall v \in V : a*(b*v)=(a*b)*v$
	\item $\forall a, b \in K \forall u, v \in V : a*(u+v)=a*u+a*v$
	\item $\forall a, b \in K \forall u, v \in V : (a+b)*v=a*v+b*v$
\end{enumerate}

\subsection*{Untervektorräume}

$K$-Untervektorraum $U$ von $V$ ist Teilmenge $U \subseteq V$ die bzgl. Addition Untergruppe von $V$ ist und für die gilt: $\forall a \in K, u \in U : a*u \in U$ (d.h. skalare Multiplikation geschlossen)

\subsubsection*{Untervektorraumkriterium}

Seien $K$ Körper, $V$ $K$-Vektorraum und $U \subseteq V$. Dann ist äquivalent:

\begin{enumerate}[label=(\alph*)]
	\item $U$ ist Untervektorraum von $V$
	\item $U \neq \emptyset$, $\forall u_1, u_2 \in U : u_1 + u_2 \in U$ und $\forall a \in K, u \in U : a*u \in U$
\end{enumerate}

\subsubsection*{$\phi$-invariante Unterräume}

$U \subset V$ ist $\phi$-invariant, wenn $\phi(U) \subset U$.

\subsubsection*{Summe}

$U_1 + U_2 = {u_1+u_2 | u_1 \in U_1, u_2 \in U_2 }$ ist Summe von $U_1$ und $U_2$, kleinster UVR der $U_1 \cup U_2$ enthält.

$dim(U_1 + U_2) = dim(U_1) + dim(U_2) - dim(U_1 \cap U_2)$

\subsubsection*{Direkte Summe}

$U_1 + U_2$ ist direkte Summe, wenn $U_1 \cap U_2 = {0}$.

d.h. gdw. der Schnitt eines UVR mit der Summe aller anderen UVR nur den Nullvektor enthält.

$dim(U_1 \oplus U_2)=dim(U_1)+dim(U_2)$

\subsection*{Homomorphismen}

Seien $V, W$ zwei $K$-Vektorräume. $\phi : V \rightarrow W$ ist Vektorraumhomomorphismus respektive $K$-lineare Abbildung, wenn:

\begin{enumerate}[label=(\alph*)]
	\item $\forall u, v \in  V : \phi(u+v) = \phi(u)+\phi(v)$
	\item $\forall a \in K, v \in V : \phi(a*v) = a*\phi(v)$
\end{enumerate}

$Rang(\phi) := dim(Bild(\phi))$ mit $\phi \in Hom(V, W)$

\subsection*{Basen}

Teilmenge $B \subseteq V$ ist Basis von $V$, wenn sich $\forall v \in V$ auf genau eine Art als Linearkombination von $B$ schreiben lässt. Jede Basis von $K^p$ hat genau $p$ Elemente.

\subsubsection*{Lineare Unabhängigkeit}

$\sum_{i=1}^{k} \lambda_i * v_i = 0 \Rightarrow \forall i \in \{1, \cdots, k\} : \lambda_i = 0$

\subsubsection*{Dimension}

Ist Mächtigkeit der Basis, $dim(V) := |B|$

$U$ Untervektorraum $V$, dann: $dim(U) \leq dim(V)$

$dim(V) = dim(Kern(\phi)) + dim(Bild(\phi))$

\subsubsection*{Abbildungsmatrizen}

$D_C(\phi(v)) = D_{CB}(\phi) * D_B(v)$

\subsubsection*{Basiswechselformel}

Seien $V, W$ $K$-Vektorräume; $\phi \in Hom(V, W)$; $B, \tilde B$ Basen von $V$; $C, \tilde C$ Basen von W. Dann gilt:

$D_{\tilde C \tilde B}(\phi) = D_{\tilde C C}(I_W) * D_{CB}(\phi) * D_{B\tilde B}(I_V)$

\subsection*{Dualräume}

Sei $V$ ein $K$-Vektorraum. Die Menge aller linearen Abbildungen $V \rightarrow K$ ist der Dualraum: $V^* := \{f: V \rightarrow K | f \text{ ist linear}\}$.

$f \in V^*$ werden als Linearformen bezeichnet.

\subsubsection*{Duale Basis}

Sei $B = \{b_1, \cdots, b_n\}$ Basis von $V$, dann ist $B^* = \{b_1^*, \cdots, b_n^*\}$ Basis des Dualraums $V^*$, also die zu $B$ von $V$ duale Basis.

Die für $b_i$ eindeutige Abb. $b_i^* : V \rightarrow \mathbb{K}$ erfüllt $b_i^*(b_i) = 1$ und $b_i^*(b_j) = 0$ für $j\neq i$.

\subsection*{Faktor- / Quotientenräume}

$v_1 \thicksim v_2 \Leftrightarrow v_1 - v_2 \in U$ für $v_1, v_2 \in V$ definiert Äquivalenzrelation auf $K$-Vektorraum $V$.

$v_1$ und $v_2$ sind Elemente einer Äquivalenzklasse gdw. sie sich um ein $u \in U$ unterscheiden.

$V/U := \{[v] | v \in V\}$ mit $[v] := v+U := \{v+u|u \in U\}$

$dim(V/U) = dim(V) - dim(U)$

\section*{Eigenwerte}

$A*v = \lambda * v$ wobei $\lambda \in Spec(A)$ und $v \in Eig_\lambda(A)$

\subsection*{Eigenräume}

$Eig_\lambda(A) := \{v \in K^n : A*v = \lambda * v\} = Kern(A-\lambda I_n)$

\subsection*{Charakteristisches Polynom}

$CP_A(x) = det(x*I_n - A)$

\subsection*{Minimalpolynom}

$MP_\phi(x)$ ist Teiler kleinsten Grades von $CP_\phi(x)$ welcher jeden Linearfaktor beinhaltet und für den noch $MP_\phi(\phi) = 0$ gilt.

\subsection*{Vielfachheit}

$\mu_g(\phi, \lambda) := dim(Eig_\lambda(\phi))$ ist die geometrische Vielfachheit von $\lambda$.

$\mu_a(\phi, \lambda)$ ist algebraische Vielfachheit von $\lambda$, also die Vielfachheit des Linearfaktors $(x-\lambda)$ von $CP_\phi$.

\subsection*{Diagonalisierbarkeit}

$\phi \in End(V)$ ist diagonalisierbar, wenn eines aus:

\begin{enumerate}[label=(\alph*)]
	\item $\exists$ Basis $B$ von $V$ aus Eigenvektoren von $\phi$
	\item $MP_\phi(X)$ zerfällt vollst. in Linearfaktoren
	\item $CP_\phi(X)$ zerfällt vollst. in Linearfaktoren und $\forall \lambda \in Spec(\phi) : \mu_g(\phi,\lambda) = \mu_a(\phi, \lambda)$
\end{enumerate}

\subsubsection*{Diagonalisierungsverfahren}

Eigenwerte und Eigenräume von $\phi$ bestimmen. Eigenwerte in $D_{CC}(\phi) = diag(\lambda_1, \hdots, \lambda_n)$ eintragen. $D_{CC}(\phi)$ ist Abbildungsmatrix von $\phi$ bzgl. Basis $C$ aus Eigenvektoren. $D_{BC}(Id)$ besteht aus Eigenvektoren in Spalten, $D_{CB}(Id) = D_{BC}(Id)^{-1}$.

Insgesamt: $D_{CC}(\phi) = D_{BC}(Id)^{-1} D_{BB}(\phi) D_{BC}(Id)$.

\section*{Haupträume}

$H(\phi, \lambda) = Kern((\phi - \lambda * I_n)^e)$ mit $e := \mu_a(\phi, \lambda)$.

Weiterhin gilt $dim(H(\phi, \lambda))=e$.

\section*{Bilinearformen}

\subsection*{Paarung, Bilinearform}

$P : V \times W \rightarrow K$ ist Paarung von $V$ und $W$, wenn:

\begin{enumerate}[label=(\alph*)]
	\item $P(av_1 + v_2, w_1) = aP(v_1, w_1) + P(v_2, w_1)$
	\item $P(v_1, bw_1 + w_2) = bP(v_1, w_1) + P(v_1, w_2)$
\end{enumerate}

für $\forall a, b \in K$; $v_1, v_2 \in V$; $w_1, w_2 \in W$. Diese Eigenschaft wird als Bilinearität von $P$ bezeichnet.

Falls $V=W$ heißt $P$ Bilinearform auf $V$.

\subsubsection*{Ausartung}

Paarung $P$ heißt nicht ausgeartet, wenn:

\hspace*{2mm}
$\forall v \in V, v \neq 0 \exists w \in W : P(v, w) \neq 0$

$\land$ $\forall w \in W, w \neq 0 \exists v \in V : P(v, w) \neq 0$

\subsection*{Orthogonalbasis}

Basis $B := \{b_1, ..., b_n\}$ ist Orthogonalbasis von $V$ bzgl. $P$, wenn: $\forall 1 \leq i \neq j \leq n : P(b_i, b_j) = 0$

\subsection*{Orthonormalbasis}

Orthogonalbasis $B$ ist Orthonormalbasis von $V$ bzgl. $P$, wenn: $\forall 1 \leq i \leq n : P(b_i, b_i) = 1$

\section*{Jordansche Normalform $\tilde A = T^{-1} A T$}

\subsection*{Darstellungsmatrix $\tilde A$ bzgl. Jordanbasis}

\begin{enumerate}[leftmargin=4mm]
	\item Eigenwerte aus char. Polynom bestimmen
	\item Länge des Blocks zu Eigenwert ist $\mu_a(\lambda)$
	\item Anzahl Kästchen pro Block ist $\mu_g(\lambda)$
	\item Kleinstes $p$ mit $Kern((A-\lambda I)^p) = Kern((A-\lambda I)^{p+1})$ ist Länge des größten Kästchens zu $\lambda$
	\item Kästchen der Größe nach sortieren, Eigenwerte auf Hauptdiagonale
	\item Anzahl der Jordankästchen mit Größe $s$ ergibt sich aus $2a_s - a_{s-1} - a_{s+1}$ mit $a_s = dim(Kern((A-\lambda I)^s))$
\end{enumerate}

\subsection*{Bestimmung Basiswechselmatrix $T$}

Reichen die Eigenvektoren nicht aus, können Hauptvektoren hinzugezogen werden. Dazu wähle Hauptvektor $v_1$ $p$-ter Stufe wobei $p$ Länge des größten Kästchens zu $\lambda$ ist. $v_1$ kann direkt verwendet werden, weitere Vektoren ergeben sich als $v_{i+1} = (A-\lambda I)*v_i$.

\section*{Skalarprodukte}

\subsection*{Standardskalarprodukt auf $\mathbb{R}^n$}

$\langle \cdot, \cdot \rangle : \mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}, \langle v, w \rangle := v^T * w$

\subsection*{Positive Definitheit}

Eine symmetrische Bilinearform $\langle \cdot, \cdot \rangle : V \times V \rightarrow \mathbb{R}$ ist positiv definit, wenn:

$\forall v \in V: v \neq 0 \Rightarrow \langle v, v \rangle > 0$

\subsection*{Skalarprodukt auf $V$}

Ein Skalarprodukt auf $V$ ist symmetrische, positiv definite Bilinearform. Ein reeller Vektorraum mit Skalarprodukt ist euklidischer Vektorraum.

\begin{description}[leftmargin=!,labelwidth=10mm]
	\item[Norm]   $||v|| := \sqrt{\langle v, v \rangle}$
	\item[Metrik] $d(v, w) := ||v - w||$
\end{description}

\subsection*{Komplexes Skalarprodukt}

$\langle \cdot, \cdot \rangle : V \times V \rightarrow \mathbb{C}$ ist komplexes SKP, wenn:

\begin{enumerate}[label=(\alph*)]
	\item $\forall v_1, v_2, w \in V, a \in \mathbb{C} : \text{(linear)} \\ \hspace*{4mm} \langle av_1 + v_2, w \rangle = a \langle v_1, w \rangle + \langle v_2, w \rangle$
	\item $\forall v_1, v_2, w \in V, a \in \mathbb{C} : \text{(semilinear)} \\ \hspace*{4mm} \langle w, av_1 + v_2 \rangle = \overline a \langle w, v_1 \rangle + \langle w, v_2 \rangle$
	\item $\forall v, w \in V : \langle v, w \rangle = \overline{\langle w, v \rangle} \text{ (hermitesch)}$
	\item $\forall v \in V \setminus \{0\} : \langle v, v \rangle > 0$
\end{enumerate}

Wobei (a) und (b) Sesquilinearität, (c) Hermitizität und (d) Positivität. Ein komplexer Vektorraum mit komplexem SKP ist unitärer Vektorraum.

\subsubsection*{Standardskalarprodukt auf $\mathbb{C}^n$}

$\mathbb{C}^n \times \mathbb{C}^n \ni (v, w) \mapsto \langle v, w \rangle := v^T * \overline w = \sum_{i=1}^n v_i * \overline{w_i}$

\subsection*{Fundamentalmatrix}

Seien $B$ und $C$ Basen von $V$ und $\langle \cdot, \cdot \rangle$ SKP.

\vspace*{-3mm}
$$D_{BC}(\langle \cdot, \cdot \rangle) = \begin{pmatrix}
	\langle b_1, c_1 \rangle & \hdots & \langle b_1, c_n \rangle \\
	\vdots & \ddots & \vdots \\
	\langle b_n, c_1 \rangle & \hdots & \langle b_n, c_n \rangle
\end{pmatrix}$$

\subsubsection*{Hurwitz-Kriterium}

Eine symmetrische bzw. hermitesche Matrix $A$ ist positiv definit gdw. die Determinanten aller führenden Hauptminoren positiv sind. Führende Hauptminoren sind in der oberen linken Ecke beginnende quadr. Teilmatr. von $A$ inkl. $A$ selbst.

\subsection*{Ungleichung von Cauchy-Schwarz}

$\langle v, w \rangle ^2 \leq \langle v, v \rangle * \langle w, w \rangle$ (in $\mathbb{R}$)

$|\langle v, w \rangle |^2 \leq \langle v, v \rangle * \langle w, w \rangle$ (in $\mathbb{C}$)

\subsection*{Satz des Pythagoras}

$||v+w||^2 = \langle v, v \rangle + 2\langle v, w \rangle + \langle w, w \rangle$

\subsubsection*{Orthogonalität}

$v \perp w \Leftrightarrow ||v||^2 + ||w||^2 = ||v+w||^2$

\subsection*{Orthogonalisierung mit Gram-Schmidt}

Sei $V$ euklidischer Vektorraum und $\{v_1, ..., v_k\} \subset V$ linear unabhängige Teilmenge mit $k$ Elementen.

\vspace*{-4mm}
$$w_1 := v_1, w_l := v_l - \sum_{i=1}^{l-1} \frac{\langle v_l, w_i \rangle}{\langle w_i, w_i\rangle}*w_i \text{ (für } l = 2, ..., k)$$

Dann ist $S := \{w_1, ..., w_k\}$ Orthogonalsystem in $V$.

$\tilde S := \{\frac{1}{||w_1||}*w_1, ..., \frac{1}{||w_k||}*w_k$ ist Orthonormalsystem.

Im unitären Standardraum $\mathbb{C}^n$ ist Basis $B = \{b_1, ..., b_n\}$ ONB gdw. für Matrix $A$ mit Basisvektoren als Spalten $A^T*\overline A = I_n$ gilt.

\subsubsection*{Fourierformel}

Sei $B$ ONB von $V$ und $\langle \cdot, \cdot \rangle$ Paarung, dann:

$v \in V \Rightarrow v = \sum_{b\in B} \langle v, b \rangle \cdot b$

Insbesondere ist $v$ bzgl. ONB $B$ dann:

$D_B(v) = (\langle v, b_i\rangle)_{1\leq i \leq n}$

\subsubsection*{Orthogonalräume}

Sei $V$ euklidischer Vektorraum und $M \subseteq V$.

\vspace*{-2mm}
\begin{equation*}
	\begin{aligned}
		M^{\perp} :&= \{v \in V | \forall m \in M : m \perp v \} \\
		           &= \{v \in V | \forall m \in M : \langle v, m \rangle = 0\}
	\end{aligned}
\end{equation*}

$M^{\perp}$ ist Untervektorraum von $V$. Auch gilt:

\begin{enumerate}[label=(\alph*)]
	\item $N \subseteq M \Rightarrow M^{\perp} \subseteq N^{\perp}$
	\item $M^{\perp} = \langle M \rangle ^{\perp}$
\end{enumerate}

\subsubsection*{Orthogonales Komplement}

Sei $U$ Untervektorraum von euklidischem Raum $V$, dann $U^\perp$ orthogonales Komplement zu $U$.

Entsprechend gilt: $V = U \oplus U^\perp$

\subsubsection*{Orthogonale Projektionen}

\begin{description}[leftmargin=!,labelwidth=20mm]
	\item[Definition] $\Pi_U : V \rightarrow U, u + u^\perp \mapsto u$
	\item[Bestimmung] $\Pi_U(a) = \sum_{i=1}^n \langle a,u_i \rangle u_i$
	\item[Abstand]    $d(a, U) = ||u^\perp|| = ||a - \Pi_U(a)||$
\end{description}

\subsubsection*{Orthogonale Matrizen}

$A$ heißt orthogonal, wenn $A^TA=I$ gilt.

$A$ ist orthogonale Matrix $\Rightarrow det(A)=\pm 1$

$\forall \lambda \in Spec(A) : \lambda=\pm 1$

Orthogonale Matrizen sind normal.

\subsubsection*{Unitäre Matrizen}

$A$ heißt unitär, wenn $\overline{A^T}A = I$ gilt.

$A$ ist unitäre Matrix $\Rightarrow |det(A)|=1$

$\forall \lambda \in Spec(A) : |\lambda| = 1$

Unitäre Matrizen sind normal.

\subsection*{Iwasawa- / QR-Zerlegung}

Zerlegung von $A \in GL_n(\mathbb{K})$ in das Produkt aus einer orthogonalen bzw. unitären Matrix und einer oberen Dreiecksmatrix. $A = Q \cdot R$.

\vspace*{-5mm}
$$A = \begin{pmatrix}
\vdots & \vdots                           & \vdots \\
q_1    & \hspace{-3mm}\hdots\hspace{-3mm} & q_n \\
\vdots & \vdots                           & \vdots
\end{pmatrix}
\begin{pmatrix}
\langle q_1, a_1 \rangle & \langle q_1, a_2 \rangle & \hdots & \langle q_1, a_n \rangle \\
0                        & \langle q_2, a_2 \rangle & \hdots & \langle q_2, a_n \rangle \\
\vdots                   & \vdots                   & \ddots & \vdots                   \\
0                        & 0                        & \hdots & \langle q_n, a_n \rangle
\end{pmatrix}$$

\vspace*{-2mm}
\begin{enumerate}[leftmargin=4mm]
	\item Spalten von $A$ orthonormalisieren
	\item $Q$ sind die orthonormalisierten Spalten von $A$
	\item Beträge der orthogonalen aber nicht normalisierten Spalten von $A$ bilden Hauptdiagonale von $R$
	\item Skalarprodukte von Spalten $Q$ mit Spalten $A$ bilden obere Dreieckswerte
\end{enumerate}

\section*{Isometrien}

Für metrische Räume $(X, d)$ und $(Y, e)$ ist $\phi : X \rightarrow Y$ eine Isometrie oder abstandserhaltende Abbildung, wenn:

$\forall x_1, x_2 \in X : d(x_1, x_2) = d(\phi(x_1), \phi(x_2))$

$Iso(X, d)$ ist die Menge aller invertierbaren Isometrien von $X$ nach $X$.

\subsection*{Lineare Isometrien}

Es seien $V, W$ euklidische oder unitäre Vektorräume. Dann ist Isometrie $\phi : V \rightarrow W$, die gleichzeitig lineare Abbildung ist, eine lineare Isometrie.

\subsection*{Eigenwerte von Isometrien}

Seien $\mathbb{K} \in \{\mathbb{R}, \mathbb{C}\}$ und $V$ ein $K$-Vektorraum mit Skalarprodukt, dann:

\begin{enumerate}[label=(\alph*)]
	\item $\phi$ ist lineare Isometrie von $V$, dann $\forall \lambda \in Spec(\phi): |\lambda|=1$
	\item $\alpha \in \mathbb{K}$ mit $|\alpha|=1 \land V \neq \{0\}$, dann gibt es Isometrie von $V$ mit Eigenwert $\alpha$
\end{enumerate}

\subsection*{Isometrien und Orthonormalbasen}

Sei $V$ endl. dim. VRaum mit SKP, $\phi \in End(V)$ und $B$ ONB, dann:

\vspace*{-5mm}
\begin{align*}
	\phi \text{ ist Isometrie } &\Leftrightarrow \phi(B) \text{ ist ONB von } V \\
							    &\Leftrightarrow D_{BB}(\phi) \text{ orthogonal / unitär}
\end{align*}

\subsection*{Isometrienormalform}

Sei $A \in U(n)$, dann gibt es $S \in U(n)$, sodass $S^{-1} A S$ Diagonalmatrix.

Sei $A \in O(n)$, $d_+ := dim(Eig(A,1))$, $d_- := dim(Eig(A, -1))$ und $l = \frac{1}{2}(n - d_+ - d_-)$, dann existiert $S \in O(n)$, sodass $S^{-1} A S$ die folgende Blockgestalt hat:

$$\begin{pmatrix}
I_{d_+} & 0        & \hdots     & \hdots & 0      \\
0       & -I_{d_i} & \ddots     & \ddots & \vdots \\
\vdots  & \ddots   & D_{\psi_1} & \ddots & \vdots \\
\vdots  & \ddots   & \ddots     & \ddots & 0      \\
0       & \hdots   & \hdots     & 0      & D_{\psi_l}
\end{pmatrix}$$

Wobei $D_{\psi_i} = \begin{pmatrix} cos(\psi_i) & -sin(\psi_i) \\ sin(\psi_i) & cos(\psi_i) \end{pmatrix}$ Drehkästchen.

\subsubsection*{Bestimmung Isometrienormalform}

\begin{enumerate}[leftmargin=4mm]
	\item Reelle und komplexe Eigenwerte bestimmen
	\item Hauptdiagonale mit reellen Eigenwerten entsprechend $\mu_a$ befüllen
	\item Drehkästchen abhg. der komplexen Eigenwerte bestimmen wobei $cos(\psi)$ dem reellen und $sin(\psi)$ dem komplexen Anteil enstspricht
	\item $S$ wird aus Orthonormalbasen der Eigenräume zusammengesetzt
\end{enumerate}

\section*{Selbstadjungierte Abbildungen}

Sei $V$ Vektorraum mit SKP über $\mathbb{R}$ oder $\mathbb{C}$ und $\phi \in End(V)$. Dann ist $\phi$ selbstadjungiert, wenn für $\forall v, w \in V$ gilt: $\langle \phi(v), w \rangle = \langle v, \phi(w) \rangle$.

$\phi \text{ ist selbstadjungiert} \Leftrightarrow D_{BB}(\phi)=\overline{D_{BB}(\phi)^T}$

Orthogonale Projektion $\pi$ ist selbstadjungiert.

\subsection*{Hermitesche Matrizen}

$A^* := \overline{A^T}$, $A = A^* \Leftrightarrow A \text{ ist hermitesch}$

\subsection*{Normale Matrizen}

Sei $A \in \mathbb{C}^{n\times n}$, dann: $A^* \cdot A = A \cdot A^*$

Sei $B \in \mathbb{R}^{n\times n}$, dann: $B^T \cdot B = B \cdot B^T$

Normale Matrizen sind unitär diagonalisierbar.

\subsection*{Symmetrische reelle Matrizen}

Eine symmetrische Matrix $A \in \mathbb{R}^{n\times n}$ besitzt ausschließlich reelle Eigenwerte.

Es existiert eine orthogonale Matrix $S \in O(n)$ so, dass $D_A = S^TAS$ eine Diagonalmatrix ist.

\subsection*{Spektralsatz}

Sei $V$ Vektorraum über $\mathbb{R}$ oder $\mathbb{C}$ mit SKP und $\phi \in End(V)$. Dann ist äquivalent:

\begin{enumerate}[label=(\alph*)]
	\item $\phi$ ist selbstadjungiert
	\item Es gibt eine Orthonormalbasis aus Eigenvektoren von $\phi$ und $Spec(\phi) \subset \mathbb{R}$
\end{enumerate}

\subsubsection*{Positivität}

Eine symmetrische Matrix $A \in \mathbb{R}^{n \times n}$ ist positiv definit gdw. $\forall \lambda \in Spec(A) : \lambda \geq 0$

\section*{Affine Räume}

Sei $V$ ein $K$-Vektorraum, $A \neq \emptyset$ und $\tau : V \times A \rightarrow A$. Dann ist $(A, V, \tau)$ ein affiner Raum  mit Translationsvektorraum $V$ und Addition $\tau$, wenn:

\begin{enumerate}[label=(\alph*)]
	\item $\forall P \in A : \tau(0, P) = P$
	\item $\forall P \in A \forall v_1, v_2 \in V : \\ \hspace*{5mm} \tau(v_1, \tau(v_2, P)) = \tau((v_1 + v_2), P)$
	\item $\forall P, Q \in A \exists ! v \in V : \tau(v, P) = Q$
\end{enumerate}

Hinweis: $A$ kann aber muss kein Vektorraum sein.

\subsection*{Affine Teilräume}

$A := v + W$ ist affiner Teilraum von $V$ mit $W \leq V$ Vektorräume und $v \in V$. Dies entspricht dem nichtleeren Lösungsraum $\mathcal{L}(A,b)$ eines LGS.

\subsubsection*{Lot, Lotfußpunkte}

Seien $A=x_0+\langle x_1,...,x_r \rangle$, $B=y_0+\langle y_1,...,y_s\rangle$ affine UR, das Lot ist die Strecke zwischen den Lotfußpunkten.

Sei $C=(x_1,...x_r,y_1,...y_r)$, dann ergibt die Lösung $z=(-\lambda_1,...,-\lambda_r,\mu_1,...,\mu_s)^T$ von $C^TCz=C^T(x_0-y_0)$ die Lotfußpunkte $P=x_0+\sum_{i=1}^r \lambda_i x_i$ und $Q=y_0+\sum_{i=1}^s \mu_1 y_i$. Weiterhin ist $d(A, B)=d(P,Q)$.

\subsubsection*{Affine Geraden}

Seien $a, b \in V$, dann ist die affine Gerade durch $a$ und $b$: $\overline{a, b} := \{\lambda a + (1 - \lambda)b | \lambda \in K\} = a + K*(b-a)$

Für $K = \mathbb{R}$ und $a, b \in V$ wobei $V$ $\mathbb{R}$-Vektorraum:

$[a, b] := \{\lambda a + (1 - \lambda)b|0 \leq \lambda \leq 1\}$ (Strecke $\overrightarrow{ab}$)

\subsection*{Affine Abbildungen, Affinitäten}

Seien $A$, $B$ affine Räume mit Translationsvektorräumen $V$ und $W$ über $\mathbb{K}$. Abbildung $\phi : A \rightarrow B$ induziert für gewähltes $a \in A$ eine Abbildung $\varphi : V \rightarrow W$ mit $\phi(v+a) = \varphi(v) + \phi(a)$.

$\phi$ heißt affiner Homomorphismus falls $\varphi$ ein Vektorraumhomomorphismus ist. Invertierbares $\phi$ heißt Affinität.

\subsubsection*{Affiner Standardraum $\mathbb{A}^n(\mathbb{K})$}

Alle affinen Selbstabbildungen des affinen Standardraums haben die Gestalt $\phi : A \rightarrow A$ mit $\phi(a) := M \cdot a + t$ für bel. $M \in \mathbb{K}^{n\times n}$ und $t \in \mathbb{K}^n$.

\subsubsection*{Euklidischer Raum}

Ist $A$ affiner Raum mit $\mathbb{R}$-Vektorraum $V$ als euklidischen Translationsvektorraum, dann ist $A$ ein euklidischer Raum.

\subsection*{Quadriken}

Eine Quadrik $Q \subseteq \mathbb{K}^n$ ist $Q := \{ v \in \mathbb{K}^n | F(v) = 0 \}$ wobei $F \in \mathbb{K}[X_1, \cdots, X_n]$ quadratisches Polynom.

\subsubsection*{Matrizenform}

Das eine Quadrik $Q$ definierende quadratische Polynom lässt sich wie folgt darstellen:

$F(x) = x^TAx + b^Tx + c$ mit $A \in \mathbb{K}^{n\times n}$, $b \in \mathbb{K}^n$

Für $char(\mathbb{K})\neq 2$ ist $A$ symmetrisch.

\subsubsection*{Affine Normalform}

Ziel der Bestimmung einer möglichst einfachen affinen Normalform $\tilde Q$ von $Q$ sowie einer Affinität $\varphi$ welche $Q$ in diese Normalform überführt.

\begin{enumerate}[leftmargin=4mm]
	\item $F(x)$ als $F(x) = x^TAx + 2b^Tx + \gamma$ schreiben
	\item $A$ diagonalisieren mit $\tilde A = C^TAC$
	\item Bestimme Mittelpunkt $d$ in $A \cdot d=-b$
	\item Bestimme konstanten Term $F(d)$
	\item $\varphi(x)=Cx+d$ ist gesuchte Affinität
	\item $\tilde F(x) = (F \circ \varphi)(x) = x^T\tilde Ax+F(d)$ durch konstanten Term teilen um $\tilde Q$ zu erhalten.
\end{enumerate}

Somit wird $F(x)=x^TAx+2b^Tx+\gamma$ mittels $\varphi(x)=Cx+d$ in $(F \circ \varphi)(x)=x^T\tilde Ax+2\tilde b^Tx + \tilde\gamma$ überführt.

Dabei gilt $\tilde A = C^TAC$, $\tilde b = C^T(Ad+b)$ und $\tilde\gamma = F(d)$.

\subsubsection*{Euklidische Normalform}

Ähnlich affiner Normalform, Transformation nur mit Isometrie $\varphi(x)=Cx+d$ wobei $C \in O(n)$ also Orthogonalbasis aus Eigenvektoren von $A$.

\begin{enumerate}[leftmargin=4mm]
	\item $F(x)$ als $F(x) = x^TAx + 2b^Tx + \gamma$ schreiben
	\item $A$ diagonalisieren mit $\tilde A = C^TAC$
	\begin{enumerate}[leftmargin=4mm,label=(\roman*)]
		\item Eigenwerte, -vektoren von $A$ bestimmen
		\item Eigenvektoren orthonormalisieren
		\item Orthonormalisieren benötigt hier nur Normalisieren da die Orthogonalität zwischen Eigenvektoren verschiedener Eigenwerte bei Selbstadjungiertheit von $A$ gegeben ist
	\end{enumerate}
	\item Alles weitere analog zu affiner Normalform
\end{enumerate}
